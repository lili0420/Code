安装Hadoop完全分布式:
一、配置第一台的主机名为自己的名字拼音lili1，用户名设置为管理员lili
二、进入Centos7的Linux系统，然后ping www.baidu.com，查看网络是否连接，如果无法连接，那么就重新装过Centos7
三、设置静态IP
vim /etc/sysconfig/network-scripts/ifcfg-ens33
修改：
把BOOTPROTO="none"修改成BOOTPROTO="static"
四、关闭防火墙
关闭防火墙：systemctl stop firewalld
查看防火墙的状态：systemctl status firewalld
禁用防火墙：systemctl disable firewalld(*注意：防火墙一定要停止运行）

五、修改主机名
vim /etc/hostname
改成自己名字的拼音
reboot（生效）

六、配置主机名与IP映射
vim /etc/hosts 
加入：
主机IP地址    主机名（即自己名字的拼音）
**注：要配置三台机的主机名与IP映射

七、
关闭第一台主机，然后右击管理-克隆第一台、第二台从机，名字为lili2、lili3,在两台从机上进行如下操作：
（1）ping www.baidu.com，查看网络是否连接，如果无法连接，那么就重新装过Centos7
(2)设置静态IP
把IPADDRESS修改成第六点配置好的
(3)修改主机名
vim /etc/hostname
改成lili2(lili3),
然后reboot生效


八、在第一台主机上设置SSH免密登录
ssh-keygen -t rsa
ssh-copy-id lili1
ssh-copy-id lili2
ssh-copy-id lili3
ssh lili1
ssh lili2
ssh lili3
ping lili1
ping lili2
ping lili3

八、用Xftp7软件把jdk和hadoop的安装包上传到Linux系统
注：用Winodows宿主机ping一下虚拟机的ip地址，如果ping不通的话Xshell和Xftp就无法连接虚拟机了

九、在第一台主机上（即lili1)安装JAVA运行环境
在/opt目录下创建apps、module目录
然后解压、改名、配置环境
tar -zxvf xxxxxxxxxxx.tar.gz -C 路径(即/opt/apps)
mv xxx jdk
mv xxx hadoop


vim /etc/profile配置环境：
#JAVA_HOME
export JAVA_HOME=路径
export JRE_HOME=${JAVA_HOME}/jre
export PATH=$PATH:$JAVA_HOME/bin
#HADOOP_HOME
export HADOOP_HOME=路径
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
接着source /etc/profile

十、在第一台主机上(即lili1) 配置好5个文件：hadoop-env.sh,core-site.xml,hdfs-site.xml,yarn-site.xml,mapred-site.xml,workers
(1)hadoop-env.sh:
添加：
export JAVA_HOME=jdk的目录
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
(2)core-site.xml
 <!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs:/主机名:8020</value>
    </property>
    <!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>Hadoop.tmp.dir</name>
        <value>hadoop路径/tmp</value>
</property>
(3)hdfs-site.xml
		<property>
                <name>dfs.namenode.name.dir</name>
                <value>/opt/apps/hadoop/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/opt/apps/hadoop/tmp/dfs/data</value>
        </property>
        <property>
                <name>dfs.resplication</name>
                <value>3</value>
        </property>
(4)yarn-site.xml
		<!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>主机名</value>
    </property>
（5）mapred-site.xml
<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
(6)workers
lili1
lili2
lili3


十一、在第一台主机(lili1)分发文件到第二、三台从机上:
scp -r /etc/profile root@lili2:/etc/profile
scp -r /etc/profile root@lili3:/etc/profile
scp -r /opt/apps/ root@lili2:/opt/apps
scp -r /opt/apps/ root@lili3:/opt/apps
接着在第二、三台从机检验java、hadoop版本
命令如下:
java -version
hadoop version
(注：如果查不到版本，那么就source /etc/profile,刷新文件，使之生效)


十二、在第一台主机(lili1)进行格式化namenode:
hdfs namenode -format

十二、接着在/opt/apps/hadoop/sbin目录下：./start-all.sh
然后jps(查看有6个进程)说明成功了

十三、在第二、三台主机上jps一下，有3个进程说明成功了，分别是datanode,jps,nodemanager

十四、在网址上输入主机名/主机IP地址：9870可以访问web端地址(在Web端查看HDFS的NameNode)
主机名/主机IP地址：8088可以访问调度器（在Web端查看YARN的ResourceManager）

十五、
hdfs dfs -ls / ：查看hdfs根目录下的文件，如果没有的话，说明成功了
查看hadoop的日志文件：cd /opt/apps/hadoop/logs